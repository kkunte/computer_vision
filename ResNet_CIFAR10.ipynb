{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MLDvfKytcmW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JpLCi6OuAV-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train size 391 Test size 313\n"
     ]
    }
   ],
   "source": [
    "cifar10_train_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "     torchvision.transforms.RandomHorizontalFlip(),\n",
    "     torchvision.transforms.RandomCrop(32,4),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))        \n",
    "     #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))        \n",
    "    ])\n",
    "\n",
    "cifar10_test_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))    \n",
    "     #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))                \n",
    "    ])\n",
    "\n",
    "cifar_train_ds = torchvision.datasets.CIFAR10('./data/', train=True, transform=cifar10_train_transform, target_transform=None, download=True)\n",
    "cifar_test_ds = torchvision.datasets.CIFAR10('./data/', train=False, transform=cifar10_test_transform, target_transform=None, download=True)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(cifar_train_ds, batch_size=128,\n",
    "                                          shuffle=True, num_workers=16)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(cifar_test_ds, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "print(\"Train size {} Test size {}\".format(len(trainloader),len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_tQhRryIwtAN",
    "outputId": "f53e2847-a1d6-43fd-9fd1-b821d89292dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape torch.Size([128, 3, 32, 32]) Label shape torch.Size([128])\n",
      "Labels tensor([6, 4, 8, 7, 2, 8, 5, 6, 2, 6, 6, 6, 7, 9, 6, 9, 9, 2, 1, 6, 5, 0, 9, 2,\n",
      "        4, 6, 7, 9, 2, 7, 4, 8, 0, 3, 6, 1, 8, 8, 9, 3, 4, 6, 7, 8, 9, 7, 8, 1,\n",
      "        5, 7, 8, 4, 3, 5, 4, 5, 0, 8, 9, 0, 8, 6, 4, 7, 0, 1, 1, 0, 9, 4, 3, 6,\n",
      "        1, 0, 6, 7, 0, 6, 2, 5, 7, 2, 5, 6, 0, 5, 0, 9, 6, 3, 6, 9, 6, 6, 6, 5,\n",
      "        9, 2, 9, 3, 9, 1, 0, 1, 8, 3, 5, 0, 0, 9, 0, 4, 6, 2, 9, 7, 5, 7, 6, 8,\n",
      "        9, 1, 4, 5, 3, 7, 5, 9])\n",
      "Image shape torch.Size([128, 3, 32, 32]) Label shape torch.Size([128])\n",
      "Labels tensor([7, 4, 7, 4, 4, 6, 3, 0, 9, 1, 6, 9, 3, 8, 0, 8, 6, 8, 2, 6, 3, 7, 1, 0,\n",
      "        9, 4, 9, 6, 4, 7, 5, 5, 0, 3, 9, 5, 1, 1, 6, 3, 1, 5, 5, 8, 8, 5, 7, 6,\n",
      "        2, 9, 4, 0, 2, 2, 4, 2, 1, 1, 3, 0, 8, 0, 4, 9, 8, 1, 3, 6, 5, 5, 8, 6,\n",
      "        7, 9, 3, 5, 4, 0, 9, 8, 5, 7, 5, 5, 2, 4, 2, 5, 3, 8, 2, 4, 5, 8, 5, 8,\n",
      "        9, 5, 1, 4, 0, 8, 1, 0, 6, 3, 8, 9, 4, 2, 8, 4, 6, 0, 2, 2, 9, 7, 5, 9,\n",
      "        4, 4, 4, 4, 4, 9, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(\"Image shape {} Label shape {}\".format(images.shape,labels.shape))\n",
    "print(\"Labels {}\".format(labels))\n",
    "\n",
    "testiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "print(\"Image shape {} Label shape {}\".format(images.shape,labels.shape))\n",
    "print(\"Labels {}\".format(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mGKZQH7pvh0V",
    "outputId": "081c9752-927e-460b-bb1a-5ca176ee5338"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "            Conv2d-6           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
      "     ResidualBlock-8           [-1, 16, 32, 32]               0\n",
      "            Conv2d-9           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-10           [-1, 16, 32, 32]              32\n",
      "           Conv2d-11           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
      "    ResidualBlock-13           [-1, 16, 32, 32]               0\n",
      "           Conv2d-14           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-15           [-1, 16, 32, 32]              32\n",
      "           Conv2d-16           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-17           [-1, 16, 32, 32]              32\n",
      "    ResidualBlock-18           [-1, 16, 32, 32]               0\n",
      "      ResNetBlock-19           [-1, 16, 32, 32]               0\n",
      "           Conv2d-20           [-1, 32, 16, 16]           4,640\n",
      "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
      "           Conv2d-22           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-23           [-1, 32, 16, 16]              64\n",
      "           Conv2d-24           [-1, 32, 16, 16]             544\n",
      "      BatchNorm2d-25           [-1, 32, 16, 16]              64\n",
      "    ResidualBlock-26           [-1, 32, 16, 16]               0\n",
      "           Conv2d-27           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-28           [-1, 32, 16, 16]              64\n",
      "           Conv2d-29           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-30           [-1, 32, 16, 16]              64\n",
      "    ResidualBlock-31           [-1, 32, 16, 16]               0\n",
      "           Conv2d-32           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-33           [-1, 32, 16, 16]              64\n",
      "           Conv2d-34           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      "    ResidualBlock-36           [-1, 32, 16, 16]               0\n",
      "      ResNetBlock-37           [-1, 32, 16, 16]               0\n",
      "           Conv2d-38             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-39             [-1, 64, 8, 8]             128\n",
      "           Conv2d-40             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-41             [-1, 64, 8, 8]             128\n",
      "           Conv2d-42             [-1, 64, 8, 8]           2,112\n",
      "      BatchNorm2d-43             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-44             [-1, 64, 8, 8]               0\n",
      "           Conv2d-45             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-46             [-1, 64, 8, 8]             128\n",
      "           Conv2d-47             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-49             [-1, 64, 8, 8]               0\n",
      "           Conv2d-50             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-51             [-1, 64, 8, 8]             128\n",
      "           Conv2d-52             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-53             [-1, 64, 8, 8]             128\n",
      "    ResidualBlock-54             [-1, 64, 8, 8]               0\n",
      "      ResNetBlock-55             [-1, 64, 8, 8]               0\n",
      "        AvgPool2d-56             [-1, 64, 1, 1]               0\n",
      "          Flatten-57                   [-1, 64]               0\n",
      "           Linear-58                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 273,258\n",
      "Trainable params: 273,258\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 4.06\n",
      "Params size (MB): 1.04\n",
      "Estimated Total Size (MB): 5.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,inchannels, outchannels,biasFlag=False):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "      \n",
    "        strideForFirstLayer= int(outchannels/inchannels) #this will be int\n",
    "        \n",
    "        if strideForFirstLayer == 0 :\n",
    "            #Condition where outchannels might be less than in channels\n",
    "            strideForFirstLayer= int(inchannels/outchannels) #this will be int\n",
    "            \n",
    "        #first layer will have stride of 2 (for downsampling ) or 1\n",
    "        self.conv1 = nn.Conv2d(inchannels,outchannels, 3,strideForFirstLayer,padding=1,bias=biasFlag)\n",
    "        self.identityConn = nn.Sequential() # will be empty if inchannels== outchannels\n",
    "        if strideForFirstLayer > 1:\n",
    "            self.identityConn.add_module(\"shortcut_conv\", nn.Conv2d(inchannels,outchannels, 1,stride=strideForFirstLayer,padding=0,bias=biasFlag))\n",
    "            self.identityConn.add_module(\"shortcut_bn\",nn.BatchNorm2d(outchannels))\n",
    "            \n",
    "        self.bn1 = nn.BatchNorm2d(outchannels)\n",
    "        self.conv2 = nn.Conv2d(outchannels,outchannels, 3,stride=1,padding=1,bias=biasFlag)\n",
    "        self.bn2 = nn.BatchNorm2d(outchannels)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        origX = x\n",
    "        #main residual block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        #identity connection\n",
    "        identityX = self.identityConn(origX)\n",
    "        #add residual and identity\n",
    "        xsum = x + identityX \n",
    "        return F.relu(xsum)\n",
    "            \n",
    "class ResNetBlock(nn.Module):        \n",
    "    def __init__(self,inputCh, outputCh,numModules,biasFlag=False):\n",
    "        super(ResNetBlock,self).__init__()\n",
    "        self.seqModule = nn.Sequential()\n",
    "        #first layer is a downsample layer\n",
    "        self.seqModule.add_module(\"downsamp_layer\",ResidualBlock(inputCh,outputCh,biasFlag))\n",
    "        for i in range(1,numModules):\n",
    "            self.seqModule.add_module(\"residual_{}\".format(i),ResidualBlock(outputCh,outputCh,biasFlag))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        return self.seqModule(x)\n",
    "    \n",
    "class MyCifarResnetModel(nn.Module):        \n",
    "    def __init__(self,biasFlag=False):\n",
    "        super(MyCifarResnetModel,self).__init__()\n",
    "        self.allLayers = nn.Sequential()\n",
    "        self.allLayers.add_module(\"layer0\",nn.Conv2d(3,16,3,stride=1,padding=1,bias=biasFlag))\n",
    "        self.allLayers.add_module(\"layer0_bn\",nn.BatchNorm2d(16))\n",
    "        self.allLayers.add_module(\"layer0_relu\",nn.ReLU(True))\n",
    "        self.allLayers.add_module(\"block1\",ResNetBlock(16,16,3,biasFlag))\n",
    "        self.allLayers.add_module(\"block2\",ResNetBlock(16,32,3,biasFlag))\n",
    "        self.allLayers.add_module(\"block3\",ResNetBlock(32,64,3,biasFlag))\n",
    "        self.allLayers.add_module(\"avg_pool\",nn.AvgPool2d(8))\n",
    "        self.allLayers.add_module(\"layer7\",nn.Flatten())\n",
    "        self.allLayers.add_module(\"layer8\",nn.Linear(64,10))\n",
    "        \n",
    "        #init weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
    "            elif isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal(m.weight, std=1e-3)\n",
    "                nn.init.constant(m.bias, 0)                \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.allLayers(x)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "my_model = MyCifarResnetModel(biasFlag=True).cuda()\n",
    "summary(my_model, input_size=(3,32,32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mG9sbuiIEM88",
    "outputId": "56798412-4f40-4612-b90a-d9fd15d92f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Learning Rate [0.1]\n",
      "Epoch 0 Train Accuracy  0.3847000002861023 training time: 7.7804906368255615\n",
      "Epoch 0 Eval Accuracy  0.48179998993873596 training time: 1.2877135276794434\n",
      "Epoch 1 Learning Rate [0.1]\n",
      "Epoch 1 Train Accuracy  0.5950799584388733 training time: 7.580754518508911\n",
      "Epoch 1 Eval Accuracy  0.586899995803833 training time: 1.2424144744873047\n",
      "Epoch 2 Learning Rate [0.1]\n",
      "Epoch 2 Train Accuracy  0.678879976272583 training time: 7.596749782562256\n",
      "Epoch 2 Eval Accuracy  0.5655999779701233 training time: 1.302048683166504\n",
      "Epoch 3 Learning Rate [0.1]\n",
      "Epoch 3 Train Accuracy  0.7299399971961975 training time: 7.6442694664001465\n",
      "Epoch 3 Eval Accuracy  0.6423999667167664 training time: 1.2325327396392822\n",
      "Epoch 4 Learning Rate [0.1]\n",
      "Epoch 4 Train Accuracy  0.762779951095581 training time: 7.726342678070068\n",
      "Epoch 4 Eval Accuracy  0.7580999732017517 training time: 1.189763069152832\n",
      "Epoch 5 Learning Rate [0.1]\n",
      "Epoch 5 Train Accuracy  0.7846399545669556 training time: 7.605824708938599\n",
      "Epoch 5 Eval Accuracy  0.7935999631881714 training time: 1.2286837100982666\n",
      "Epoch 6 Learning Rate [0.1]\n",
      "Epoch 6 Train Accuracy  0.8050599694252014 training time: 7.921170711517334\n",
      "Epoch 6 Eval Accuracy  0.7354999780654907 training time: 1.2457776069641113\n",
      "Epoch 7 Learning Rate [0.1]\n",
      "Epoch 7 Train Accuracy  0.8158199787139893 training time: 7.829583168029785\n",
      "Epoch 7 Eval Accuracy  0.7811999917030334 training time: 1.2205111980438232\n",
      "Epoch 8 Learning Rate [0.1]\n",
      "Epoch 8 Train Accuracy  0.8266199827194214 training time: 7.710245132446289\n",
      "Epoch 8 Eval Accuracy  0.7714999914169312 training time: 1.2432332038879395\n",
      "Epoch 9 Learning Rate [0.1]\n",
      "Epoch 9 Train Accuracy  0.8298599720001221 training time: 7.7101218700408936\n",
      "Epoch 9 Eval Accuracy  0.8125999569892883 training time: 1.2401762008666992\n",
      "Epoch 10 Learning Rate [0.1]\n",
      "Epoch 10 Train Accuracy  0.8396399617195129 training time: 7.655900955200195\n",
      "Epoch 10 Eval Accuracy  0.8156999945640564 training time: 1.2348878383636475\n",
      "Epoch 11 Learning Rate [0.1]\n",
      "Epoch 11 Train Accuracy  0.8444799780845642 training time: 7.785049915313721\n",
      "Epoch 11 Eval Accuracy  0.8079999685287476 training time: 1.239137887954712\n",
      "Epoch 12 Learning Rate [0.1]\n",
      "Epoch 12 Train Accuracy  0.8504399657249451 training time: 7.710304260253906\n",
      "Epoch 12 Eval Accuracy  0.8255999684333801 training time: 1.2420248985290527\n",
      "Epoch 13 Learning Rate [0.1]\n",
      "Epoch 13 Train Accuracy  0.8569799661636353 training time: 7.681530714035034\n",
      "Epoch 13 Eval Accuracy  0.8203999996185303 training time: 1.2030510902404785\n",
      "Epoch 14 Learning Rate [0.1]\n",
      "Epoch 14 Train Accuracy  0.857699990272522 training time: 7.807112693786621\n",
      "Epoch 14 Eval Accuracy  0.8402000069618225 training time: 1.2366981506347656\n",
      "Epoch 15 Learning Rate [0.1]\n",
      "Epoch 15 Train Accuracy  0.8630399703979492 training time: 7.842457294464111\n",
      "Epoch 15 Eval Accuracy  0.818399965763092 training time: 1.2141950130462646\n",
      "Epoch 16 Learning Rate [0.1]\n",
      "Epoch 16 Train Accuracy  0.8671000003814697 training time: 7.732996702194214\n",
      "Epoch 16 Eval Accuracy  0.7938999533653259 training time: 1.1985080242156982\n",
      "Epoch 17 Learning Rate [0.1]\n",
      "Epoch 17 Train Accuracy  0.8675599694252014 training time: 7.757821083068848\n",
      "Epoch 17 Eval Accuracy  0.8342999815940857 training time: 1.1935944557189941\n",
      "Epoch 18 Learning Rate [0.1]\n",
      "Epoch 18 Train Accuracy  0.8718199729919434 training time: 7.7660722732543945\n",
      "Epoch 18 Eval Accuracy  0.8319999575614929 training time: 1.1646592617034912\n",
      "Epoch 19 Learning Rate [0.1]\n",
      "Epoch 19 Train Accuracy  0.8762199878692627 training time: 7.7515482902526855\n",
      "Epoch 19 Eval Accuracy  0.8017999529838562 training time: 1.2402913570404053\n",
      "Epoch 20 Learning Rate [0.1]\n",
      "Epoch 20 Train Accuracy  0.8781999945640564 training time: 7.89452052116394\n",
      "Epoch 20 Eval Accuracy  0.8440999984741211 training time: 1.2268314361572266\n",
      "Epoch 21 Learning Rate [0.1]\n",
      "Epoch 21 Train Accuracy  0.8806399703025818 training time: 7.917267322540283\n",
      "Epoch 21 Eval Accuracy  0.8517999649047852 training time: 1.35197114944458\n",
      "Epoch 22 Learning Rate [0.1]\n",
      "Epoch 22 Train Accuracy  0.8809599876403809 training time: 7.711295127868652\n",
      "Epoch 22 Eval Accuracy  0.8337000012397766 training time: 1.1892871856689453\n",
      "Epoch 23 Learning Rate [0.1]\n",
      "Epoch 23 Train Accuracy  0.8836599588394165 training time: 7.718137264251709\n",
      "Epoch 23 Eval Accuracy  0.842799961566925 training time: 1.1896536350250244\n",
      "Epoch 24 Learning Rate [0.1]\n",
      "Epoch 24 Train Accuracy  0.8848999738693237 training time: 7.884621620178223\n",
      "Epoch 24 Eval Accuracy  0.8173999786376953 training time: 1.244065761566162\n",
      "Epoch 25 Learning Rate [0.1]\n",
      "Epoch 25 Train Accuracy  0.8877999782562256 training time: 7.829858779907227\n",
      "Epoch 25 Eval Accuracy  0.8587999939918518 training time: 1.2084755897521973\n",
      "Epoch 26 Learning Rate [0.1]\n",
      "Epoch 26 Train Accuracy  0.8892999887466431 training time: 7.7927467823028564\n",
      "Epoch 26 Eval Accuracy  0.8625999689102173 training time: 1.2833702564239502\n",
      "Epoch 27 Learning Rate [0.1]\n",
      "Epoch 27 Train Accuracy  0.8901799917221069 training time: 8.026920557022095\n",
      "Epoch 27 Eval Accuracy  0.854200005531311 training time: 1.2443246841430664\n",
      "Epoch 28 Learning Rate [0.1]\n",
      "Epoch 28 Train Accuracy  0.8904599547386169 training time: 7.90505313873291\n",
      "Epoch 28 Eval Accuracy  0.8412999510765076 training time: 1.1564762592315674\n",
      "Epoch 29 Learning Rate [0.1]\n",
      "Epoch 29 Train Accuracy  0.8920599818229675 training time: 7.85984206199646\n",
      "Epoch 29 Eval Accuracy  0.8356999754905701 training time: 1.230067491531372\n",
      "Epoch 30 Learning Rate [0.1]\n",
      "Epoch 30 Train Accuracy  0.8943799734115601 training time: 7.817159652709961\n",
      "Epoch 30 Eval Accuracy  0.807699978351593 training time: 1.220470666885376\n",
      "Epoch 31 Learning Rate [0.1]\n",
      "Epoch 31 Train Accuracy  0.8951599597930908 training time: 7.8566319942474365\n",
      "Epoch 31 Eval Accuracy  0.858299970626831 training time: 1.2735857963562012\n",
      "Epoch 32 Learning Rate [0.1]\n",
      "Epoch 32 Train Accuracy  0.8959599733352661 training time: 7.937772512435913\n",
      "Epoch 32 Eval Accuracy  0.8398999571800232 training time: 1.2458603382110596\n",
      "Epoch 33 Learning Rate [0.1]\n",
      "Epoch 33 Train Accuracy  0.8973999619483948 training time: 8.199294090270996\n",
      "Epoch 33 Eval Accuracy  0.8402999639511108 training time: 1.2626008987426758\n",
      "Epoch 34 Learning Rate [0.1]\n",
      "Epoch 34 Train Accuracy  0.8962599635124207 training time: 8.118593454360962\n",
      "Epoch 34 Eval Accuracy  0.8459999561309814 training time: 1.3109631538391113\n",
      "Epoch 35 Learning Rate [0.1]\n",
      "Epoch 35 Train Accuracy  0.9002400040626526 training time: 7.836744546890259\n",
      "Epoch 35 Eval Accuracy  0.8324999809265137 training time: 1.300105094909668\n",
      "Epoch 36 Learning Rate [0.1]\n",
      "Epoch 36 Train Accuracy  0.9016000032424927 training time: 8.084258317947388\n",
      "Epoch 36 Eval Accuracy  0.8705999851226807 training time: 1.2555217742919922\n",
      "Epoch 37 Learning Rate [0.1]\n",
      "Epoch 37 Train Accuracy  0.9030399918556213 training time: 8.125791549682617\n",
      "Epoch 37 Eval Accuracy  0.8222000002861023 training time: 1.2852680683135986\n",
      "Epoch 38 Learning Rate [0.1]\n",
      "Epoch 38 Train Accuracy  0.9017599821090698 training time: 7.933514833450317\n",
      "Epoch 38 Eval Accuracy  0.8491999506950378 training time: 1.2313828468322754\n",
      "Epoch 39 Learning Rate [0.1]\n",
      "Epoch 39 Train Accuracy  0.9031199812889099 training time: 8.178519487380981\n",
      "Epoch 39 Eval Accuracy  0.8519999980926514 training time: 1.2159943580627441\n",
      "Epoch 40 Learning Rate [0.1]\n",
      "Epoch 40 Train Accuracy  0.9045599699020386 training time: 7.923609733581543\n",
      "Epoch 40 Eval Accuracy  0.8563999533653259 training time: 1.236513376235962\n",
      "Epoch 41 Learning Rate [0.1]\n",
      "Epoch 41 Train Accuracy  0.9053999781608582 training time: 7.775034427642822\n",
      "Epoch 41 Eval Accuracy  0.8435999751091003 training time: 1.201845407485962\n",
      "Epoch 42 Learning Rate [0.1]\n",
      "Epoch 42 Train Accuracy  0.904699981212616 training time: 7.9467010498046875\n",
      "Epoch 42 Eval Accuracy  0.8287000060081482 training time: 1.2878103256225586\n",
      "Epoch 43 Learning Rate [0.1]\n",
      "Epoch 43 Train Accuracy  0.9089199900627136 training time: 7.845622777938843\n",
      "Epoch 43 Eval Accuracy  0.8517000079154968 training time: 1.2104973793029785\n",
      "Epoch 44 Learning Rate [0.1]\n",
      "Epoch 44 Train Accuracy  0.907480001449585 training time: 7.842322587966919\n",
      "Epoch 44 Eval Accuracy  0.854200005531311 training time: 1.2345821857452393\n",
      "Epoch 45 Learning Rate [0.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Train Accuracy  0.9073399901390076 training time: 7.77794075012207\n",
      "Epoch 45 Eval Accuracy  0.8434000015258789 training time: 1.2235441207885742\n",
      "Epoch 46 Learning Rate [0.1]\n",
      "Epoch 46 Train Accuracy  0.906279981136322 training time: 7.789281845092773\n",
      "Epoch 46 Eval Accuracy  0.8662999868392944 training time: 1.241004228591919\n",
      "Epoch 47 Learning Rate [0.1]\n",
      "Epoch 47 Train Accuracy  0.9089399576187134 training time: 7.844830274581909\n",
      "Epoch 47 Eval Accuracy  0.8603999614715576 training time: 1.2416126728057861\n",
      "Epoch 48 Learning Rate [0.1]\n",
      "Epoch 48 Train Accuracy  0.9099799990653992 training time: 7.7651190757751465\n",
      "Epoch 48 Eval Accuracy  0.8624999523162842 training time: 1.2353122234344482\n",
      "Epoch 49 Learning Rate [0.1]\n",
      "Epoch 49 Train Accuracy  0.9107999801635742 training time: 7.79703426361084\n",
      "Epoch 49 Eval Accuracy  0.8592000007629395 training time: 1.2717218399047852\n",
      "Epoch 50 Learning Rate [0.1]\n",
      "Epoch 50 Train Accuracy  0.9091799855232239 training time: 7.880209445953369\n",
      "Epoch 50 Eval Accuracy  0.8537999987602234 training time: 1.2193050384521484\n",
      "Epoch 51 Learning Rate [0.1]\n",
      "Epoch 51 Train Accuracy  0.9135199785232544 training time: 7.930445909500122\n",
      "Epoch 51 Eval Accuracy  0.8585999608039856 training time: 1.302100419998169\n",
      "Epoch 52 Learning Rate [0.1]\n",
      "Epoch 52 Train Accuracy  0.911579966545105 training time: 7.836583614349365\n",
      "Epoch 52 Eval Accuracy  0.8690999746322632 training time: 1.241830825805664\n",
      "Epoch 53 Learning Rate [0.1]\n",
      "Epoch 53 Train Accuracy  0.911300003528595 training time: 7.788877248764038\n",
      "Epoch 53 Eval Accuracy  0.8511999845504761 training time: 1.2928640842437744\n",
      "Epoch 54 Learning Rate [0.1]\n",
      "Epoch 54 Train Accuracy  0.9121999740600586 training time: 7.7715723514556885\n",
      "Epoch 54 Eval Accuracy  0.8519999980926514 training time: 1.2555840015411377\n",
      "Epoch 55 Learning Rate [0.1]\n",
      "Epoch 55 Train Accuracy  0.9132599830627441 training time: 7.700165271759033\n",
      "Epoch 55 Eval Accuracy  0.8690999746322632 training time: 1.2298974990844727\n",
      "Epoch 56 Learning Rate [0.1]\n",
      "Epoch 56 Train Accuracy  0.914639949798584 training time: 7.758610486984253\n",
      "Epoch 56 Eval Accuracy  0.8676999807357788 training time: 1.2409536838531494\n",
      "Epoch 57 Learning Rate [0.1]\n",
      "Epoch 57 Train Accuracy  0.91211998462677 training time: 7.786121368408203\n",
      "Epoch 57 Eval Accuracy  0.8441999554634094 training time: 1.2779779434204102\n",
      "Epoch 58 Learning Rate [0.1]\n",
      "Epoch 58 Train Accuracy  0.9128999710083008 training time: 7.870707035064697\n",
      "Epoch 58 Eval Accuracy  0.843999981880188 training time: 1.1868669986724854\n",
      "Epoch 59 Learning Rate [0.1]\n",
      "Epoch 59 Train Accuracy  0.9145399928092957 training time: 7.872856378555298\n",
      "Epoch 59 Eval Accuracy  0.8417999744415283 training time: 1.2485451698303223\n",
      "Epoch 60 Learning Rate [0.1]\n",
      "Epoch 60 Train Accuracy  0.9172599911689758 training time: 7.767766237258911\n",
      "Epoch 60 Eval Accuracy  0.8588999509811401 training time: 1.240020990371704\n",
      "Epoch 61 Learning Rate [0.1]\n",
      "Epoch 61 Train Accuracy  0.9142199754714966 training time: 7.861391067504883\n",
      "Epoch 61 Eval Accuracy  0.8759999871253967 training time: 1.278381109237671\n",
      "Epoch 62 Learning Rate [0.1]\n",
      "Epoch 62 Train Accuracy  0.9160400032997131 training time: 7.874085426330566\n",
      "Epoch 62 Eval Accuracy  0.87909996509552 training time: 1.2138957977294922\n",
      "Epoch 63 Learning Rate [0.1]\n",
      "Epoch 63 Train Accuracy  0.9174999594688416 training time: 7.742576360702515\n",
      "Epoch 63 Eval Accuracy  0.8666999936103821 training time: 1.2273592948913574\n",
      "Epoch 64 Learning Rate [0.1]\n",
      "Epoch 64 Train Accuracy  0.9164999723434448 training time: 7.917243242263794\n",
      "Epoch 64 Eval Accuracy  0.8703999519348145 training time: 1.2888684272766113\n",
      "Epoch 65 Learning Rate [0.1]\n",
      "Epoch 65 Train Accuracy  0.9165599942207336 training time: 7.894066095352173\n",
      "Epoch 65 Eval Accuracy  0.8680999875068665 training time: 1.2662570476531982\n",
      "Epoch 66 Learning Rate [0.1]\n",
      "Epoch 66 Train Accuracy  0.9155799746513367 training time: 7.853521108627319\n",
      "Epoch 66 Eval Accuracy  0.8348000049591064 training time: 1.2456095218658447\n",
      "Epoch 67 Learning Rate [0.1]\n",
      "Epoch 67 Train Accuracy  0.9142799973487854 training time: 7.848229885101318\n",
      "Epoch 67 Eval Accuracy  0.8535999655723572 training time: 1.2341811656951904\n",
      "Epoch 68 Learning Rate [0.1]\n",
      "Epoch 68 Train Accuracy  0.917739987373352 training time: 7.843721151351929\n",
      "Epoch 68 Eval Accuracy  0.8604999780654907 training time: 1.2936134338378906\n",
      "Epoch 69 Learning Rate [0.1]\n",
      "Epoch 69 Train Accuracy  0.917959988117218 training time: 7.864646673202515\n",
      "Epoch 69 Eval Accuracy  0.8792999982833862 training time: 1.3425116539001465\n",
      "Epoch 70 Learning Rate [0.1]\n",
      "Epoch 70 Train Accuracy  0.9181599617004395 training time: 7.773345708847046\n",
      "Epoch 70 Eval Accuracy  0.8847000002861023 training time: 1.2126641273498535\n",
      "Epoch 71 Learning Rate [0.1]\n",
      "Epoch 71 Train Accuracy  0.9176799654960632 training time: 7.836376190185547\n",
      "Epoch 71 Eval Accuracy  0.8585000038146973 training time: 1.2227425575256348\n",
      "Epoch 72 Learning Rate [0.1]\n",
      "Epoch 72 Train Accuracy  0.9181999564170837 training time: 7.861653804779053\n",
      "Epoch 72 Eval Accuracy  0.8745999932289124 training time: 1.253208875656128\n",
      "Epoch 73 Learning Rate [0.1]\n",
      "Epoch 73 Train Accuracy  0.9185199737548828 training time: 7.802562475204468\n",
      "Epoch 73 Eval Accuracy  0.8159999847412109 training time: 1.2533893585205078\n",
      "Epoch 74 Learning Rate [0.1]\n",
      "Epoch 74 Train Accuracy  0.919219970703125 training time: 7.778758525848389\n",
      "Epoch 74 Eval Accuracy  0.8639000058174133 training time: 1.2234833240509033\n",
      "Epoch 75 Learning Rate [0.1]\n",
      "Epoch 75 Train Accuracy  0.9198799729347229 training time: 7.822978734970093\n",
      "Epoch 75 Eval Accuracy  0.8655999898910522 training time: 1.2601430416107178\n",
      "Epoch 76 Learning Rate [0.1]\n",
      "Epoch 76 Train Accuracy  0.9215999841690063 training time: 7.801430940628052\n",
      "Epoch 76 Eval Accuracy  0.871399998664856 training time: 1.1816575527191162\n",
      "Epoch 77 Learning Rate [0.1]\n",
      "Epoch 77 Train Accuracy  0.9178199768066406 training time: 7.893304824829102\n",
      "Epoch 77 Eval Accuracy  0.870199978351593 training time: 1.2291269302368164\n",
      "Epoch 78 Learning Rate [0.1]\n",
      "Epoch 78 Train Accuracy  0.9210799932479858 training time: 7.863390684127808\n",
      "Epoch 78 Eval Accuracy  0.8633999824523926 training time: 1.2096760272979736\n",
      "Epoch 79 Learning Rate [0.1]\n",
      "Epoch 79 Train Accuracy  0.9193199872970581 training time: 7.8596742153167725\n",
      "Epoch 79 Eval Accuracy  0.8675999641418457 training time: 1.2907516956329346\n",
      "Epoch 80 Learning Rate [0.1]\n",
      "Epoch 80 Train Accuracy  0.9186599850654602 training time: 7.803066968917847\n",
      "Epoch 80 Eval Accuracy  0.8671999573707581 training time: 1.2764911651611328\n",
      "Epoch 81 Learning Rate [0.1]\n",
      "Epoch 81 Train Accuracy  0.9196599721908569 training time: 7.885427474975586\n",
      "Epoch 81 Eval Accuracy  0.8782999515533447 training time: 1.272254228591919\n",
      "Epoch 82 Learning Rate [0.1]\n",
      "Epoch 82 Train Accuracy  0.9221999645233154 training time: 7.906008720397949\n",
      "Epoch 82 Eval Accuracy  0.8567000031471252 training time: 1.2145063877105713\n",
      "Epoch 83 Learning Rate [0.1]\n",
      "Epoch 83 Train Accuracy  0.9224799871444702 training time: 7.903681755065918\n",
      "Epoch 83 Eval Accuracy  0.8761999607086182 training time: 1.2306928634643555\n",
      "Epoch 84 Learning Rate [0.1]\n",
      "Epoch 84 Train Accuracy  0.9225599765777588 training time: 7.872786998748779\n",
      "Epoch 84 Eval Accuracy  0.8121999502182007 training time: 1.2440710067749023\n",
      "Epoch 85 Learning Rate [0.1]\n",
      "Epoch 85 Train Accuracy  0.9239999651908875 training time: 7.759411334991455\n",
      "Epoch 85 Eval Accuracy  0.865399956703186 training time: 1.2736945152282715\n",
      "Epoch 86 Learning Rate [0.1]\n",
      "Epoch 86 Train Accuracy  0.9235399961471558 training time: 7.850489616394043\n",
      "Epoch 86 Eval Accuracy  0.8650999665260315 training time: 1.2825961112976074\n",
      "Epoch 87 Learning Rate [0.1]\n",
      "Epoch 87 Train Accuracy  0.9215399622917175 training time: 7.971612215042114\n",
      "Epoch 87 Eval Accuracy  0.8477999567985535 training time: 1.2075929641723633\n",
      "Epoch 88 Learning Rate [0.1]\n",
      "Epoch 88 Train Accuracy  0.9205799698829651 training time: 7.851412534713745\n",
      "Epoch 88 Eval Accuracy  0.8470999598503113 training time: 1.2524521350860596\n",
      "Epoch 89 Learning Rate [0.1]\n",
      "Epoch 89 Train Accuracy  0.9236599802970886 training time: 7.756710529327393\n",
      "Epoch 89 Eval Accuracy  0.866599977016449 training time: 1.2695226669311523\n",
      "Epoch 90 Learning Rate [0.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Train Accuracy  0.9229399561882019 training time: 7.841996669769287\n",
      "Epoch 90 Eval Accuracy  0.8747999668121338 training time: 1.2659013271331787\n",
      "Epoch 91 Learning Rate [0.1]\n",
      "Epoch 91 Train Accuracy  0.9244799613952637 training time: 7.904457092285156\n",
      "Epoch 91 Eval Accuracy  0.8534999489784241 training time: 1.2703776359558105\n",
      "Epoch 92 Learning Rate [0.1]\n",
      "Epoch 92 Train Accuracy  0.9234799742698669 training time: 7.9103004932403564\n",
      "Epoch 92 Eval Accuracy  0.8434000015258789 training time: 1.2852962017059326\n",
      "Epoch 93 Learning Rate [0.1]\n",
      "Epoch 93 Train Accuracy  0.9234599471092224 training time: 7.843433141708374\n",
      "Epoch 93 Eval Accuracy  0.8761999607086182 training time: 1.256296157836914\n",
      "Epoch 94 Learning Rate [0.1]\n",
      "Epoch 94 Train Accuracy  0.9251799583435059 training time: 7.76575231552124\n",
      "Epoch 94 Eval Accuracy  0.871399998664856 training time: 1.2249460220336914\n",
      "Epoch 95 Learning Rate [0.1]\n",
      "Epoch 95 Train Accuracy  0.9224199652671814 training time: 7.847575664520264\n",
      "Epoch 95 Eval Accuracy  0.8452999591827393 training time: 1.248192548751831\n",
      "Epoch 96 Learning Rate [0.1]\n",
      "Epoch 96 Train Accuracy  0.9234199523925781 training time: 7.776131629943848\n",
      "Epoch 96 Eval Accuracy  0.8641999959945679 training time: 1.2650656700134277\n",
      "Epoch 97 Learning Rate [0.1]\n",
      "Epoch 97 Train Accuracy  0.9249399900436401 training time: 7.786096572875977\n",
      "Epoch 97 Eval Accuracy  0.835099995136261 training time: 1.256676197052002\n",
      "Epoch 98 Learning Rate [0.1]\n",
      "Epoch 98 Train Accuracy  0.9233999848365784 training time: 7.80470871925354\n",
      "Epoch 98 Eval Accuracy  0.8709999918937683 training time: 1.2523748874664307\n",
      "Epoch 99 Learning Rate [0.1]\n",
      "Epoch 99 Train Accuracy  0.9251599907875061 training time: 7.814097881317139\n",
      "Epoch 99 Eval Accuracy  0.8601999878883362 training time: 1.2727410793304443\n",
      "Epoch 100 Learning Rate [0.010000000000000002]\n",
      "Epoch 100 Train Accuracy  0.954759955406189 training time: 7.790634393692017\n",
      "Epoch 100 Eval Accuracy  0.9108999967575073 training time: 1.2112133502960205\n",
      "Epoch 101 Learning Rate [0.010000000000000002]\n",
      "Epoch 101 Train Accuracy  0.9649199843406677 training time: 7.742896318435669\n",
      "Epoch 101 Eval Accuracy  0.9150999784469604 training time: 1.2643005847930908\n",
      "Epoch 102 Learning Rate [0.010000000000000002]\n",
      "Epoch 102 Train Accuracy  0.9691399931907654 training time: 7.750235080718994\n",
      "Epoch 102 Eval Accuracy  0.9175999760627747 training time: 1.2118704319000244\n",
      "Epoch 103 Learning Rate [0.010000000000000002]\n",
      "Epoch 103 Train Accuracy  0.9716199636459351 training time: 7.836541652679443\n",
      "Epoch 103 Eval Accuracy  0.9156999588012695 training time: 1.271411418914795\n",
      "Epoch 104 Learning Rate [0.010000000000000002]\n",
      "Epoch 104 Train Accuracy  0.9728999733924866 training time: 7.803849220275879\n",
      "Epoch 104 Eval Accuracy  0.9152999520301819 training time: 1.2559552192687988\n",
      "Epoch 105 Learning Rate [0.010000000000000002]\n",
      "Epoch 105 Train Accuracy  0.9746799468994141 training time: 7.829076290130615\n",
      "Epoch 105 Eval Accuracy  0.9175999760627747 training time: 1.312502145767212\n",
      "Epoch 106 Learning Rate [0.010000000000000002]\n",
      "Epoch 106 Train Accuracy  0.9759799838066101 training time: 7.85796332359314\n",
      "Epoch 106 Eval Accuracy  0.9156000018119812 training time: 1.271244764328003\n",
      "Epoch 107 Learning Rate [0.010000000000000002]\n",
      "Epoch 107 Train Accuracy  0.9770999550819397 training time: 7.928992033004761\n",
      "Epoch 107 Eval Accuracy  0.9176999926567078 training time: 1.263070821762085\n",
      "Epoch 108 Learning Rate [0.010000000000000002]\n",
      "Epoch 108 Train Accuracy  0.9775799512863159 training time: 7.894927501678467\n",
      "Epoch 108 Eval Accuracy  0.9165999889373779 training time: 1.2878084182739258\n",
      "Epoch 109 Learning Rate [0.010000000000000002]\n",
      "Epoch 109 Train Accuracy  0.9777999520301819 training time: 7.796980619430542\n",
      "Epoch 109 Eval Accuracy  0.9172999858856201 training time: 1.278869390487671\n",
      "Epoch 110 Learning Rate [0.010000000000000002]\n",
      "Epoch 110 Train Accuracy  0.9790399670600891 training time: 7.852915048599243\n",
      "Epoch 110 Eval Accuracy  0.917199969291687 training time: 1.282843828201294\n",
      "Epoch 111 Learning Rate [0.010000000000000002]\n",
      "Epoch 111 Train Accuracy  0.9807999730110168 training time: 7.817500591278076\n",
      "Epoch 111 Eval Accuracy  0.9172999858856201 training time: 1.2372961044311523\n",
      "Epoch 112 Learning Rate [0.010000000000000002]\n",
      "Epoch 112 Train Accuracy  0.9812199473381042 training time: 7.853592872619629\n",
      "Epoch 112 Eval Accuracy  0.9179999828338623 training time: 1.2397284507751465\n",
      "Epoch 113 Learning Rate [0.010000000000000002]\n",
      "Epoch 113 Train Accuracy  0.9806999564170837 training time: 7.912139177322388\n",
      "Epoch 113 Eval Accuracy  0.9176999926567078 training time: 1.2635126113891602\n",
      "Epoch 114 Learning Rate [0.010000000000000002]\n",
      "Epoch 114 Train Accuracy  0.982699990272522 training time: 7.772062063217163\n",
      "Epoch 114 Eval Accuracy  0.9164999723434448 training time: 1.2689685821533203\n",
      "Epoch 115 Learning Rate [0.010000000000000002]\n",
      "Epoch 115 Train Accuracy  0.9828400015830994 training time: 7.817346572875977\n",
      "Epoch 115 Eval Accuracy  0.9174000024795532 training time: 1.2066051959991455\n",
      "Epoch 116 Learning Rate [0.010000000000000002]\n",
      "Epoch 116 Train Accuracy  0.983299970626831 training time: 7.835445404052734\n",
      "Epoch 116 Eval Accuracy  0.9161999821662903 training time: 1.1865234375\n",
      "Epoch 117 Learning Rate [0.010000000000000002]\n",
      "Epoch 117 Train Accuracy  0.9830399751663208 training time: 7.845781326293945\n",
      "Epoch 117 Eval Accuracy  0.9186999797821045 training time: 1.1992311477661133\n",
      "Epoch 118 Learning Rate [0.010000000000000002]\n",
      "Epoch 118 Train Accuracy  0.9839800000190735 training time: 7.9768383502960205\n",
      "Epoch 118 Eval Accuracy  0.9177999496459961 training time: 1.209444284439087\n",
      "Epoch 119 Learning Rate [0.010000000000000002]\n",
      "Epoch 119 Train Accuracy  0.9852599501609802 training time: 7.776869773864746\n",
      "Epoch 119 Eval Accuracy  0.9180999994277954 training time: 1.270721673965454\n",
      "Epoch 120 Learning Rate [0.010000000000000002]\n",
      "Epoch 120 Train Accuracy  0.9852199554443359 training time: 7.9338538646698\n",
      "Epoch 120 Eval Accuracy  0.9147999882698059 training time: 1.221388578414917\n",
      "Epoch 121 Learning Rate [0.010000000000000002]\n",
      "Epoch 121 Train Accuracy  0.9857399463653564 training time: 7.829937219619751\n",
      "Epoch 121 Eval Accuracy  0.917199969291687 training time: 1.225694179534912\n",
      "Epoch 122 Learning Rate [0.010000000000000002]\n",
      "Epoch 122 Train Accuracy  0.9860599637031555 training time: 7.825953960418701\n",
      "Epoch 122 Eval Accuracy  0.9170999526977539 training time: 1.2315959930419922\n",
      "Epoch 123 Learning Rate [0.010000000000000002]\n",
      "Epoch 123 Train Accuracy  0.9864799976348877 training time: 7.79017448425293\n",
      "Epoch 123 Eval Accuracy  0.9159999489784241 training time: 1.2433087825775146\n",
      "Epoch 124 Learning Rate [0.010000000000000002]\n",
      "Epoch 124 Train Accuracy  0.9856799840927124 training time: 7.85778284072876\n",
      "Epoch 124 Eval Accuracy  0.9161999821662903 training time: 1.2539212703704834\n",
      "Epoch 125 Learning Rate [0.010000000000000002]\n",
      "Epoch 125 Train Accuracy  0.9868800044059753 training time: 7.808892488479614\n",
      "Epoch 125 Eval Accuracy  0.9172999858856201 training time: 1.2804996967315674\n",
      "Epoch 126 Learning Rate [0.010000000000000002]\n",
      "Epoch 126 Train Accuracy  0.9878399968147278 training time: 7.774930953979492\n",
      "Epoch 126 Eval Accuracy  0.9154999852180481 training time: 1.30788254737854\n",
      "Epoch 127 Learning Rate [0.010000000000000002]\n",
      "Epoch 127 Train Accuracy  0.9882599711418152 training time: 7.920155763626099\n",
      "Epoch 127 Eval Accuracy  0.9176999926567078 training time: 1.241095781326294\n",
      "Epoch 128 Learning Rate [0.010000000000000002]\n",
      "Epoch 128 Train Accuracy  0.9872199892997742 training time: 7.814296007156372\n",
      "Epoch 128 Eval Accuracy  0.9161999821662903 training time: 1.222721815109253\n",
      "Epoch 129 Learning Rate [0.010000000000000002]\n",
      "Epoch 129 Train Accuracy  0.9879999756813049 training time: 7.845604419708252\n",
      "Epoch 129 Eval Accuracy  0.9182999730110168 training time: 1.2188258171081543\n",
      "Epoch 130 Learning Rate [0.010000000000000002]\n",
      "Epoch 130 Train Accuracy  0.988379955291748 training time: 7.94394588470459\n",
      "Epoch 130 Eval Accuracy  0.916700005531311 training time: 1.283170223236084\n",
      "Epoch 131 Learning Rate [0.010000000000000002]\n",
      "Epoch 131 Train Accuracy  0.9884799718856812 training time: 7.8703367710113525\n",
      "Epoch 131 Eval Accuracy  0.9164999723434448 training time: 1.244035005569458\n",
      "Epoch 132 Learning Rate [0.010000000000000002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 Train Accuracy  0.9889599680900574 training time: 7.903865814208984\n",
      "Epoch 132 Eval Accuracy  0.9168999791145325 training time: 1.2413058280944824\n",
      "Epoch 133 Learning Rate [0.010000000000000002]\n",
      "Epoch 133 Train Accuracy  0.9890799522399902 training time: 7.768604516983032\n",
      "Epoch 133 Eval Accuracy  0.9174000024795532 training time: 1.211235761642456\n",
      "Epoch 134 Learning Rate [0.010000000000000002]\n",
      "Epoch 134 Train Accuracy  0.9890199899673462 training time: 7.781193971633911\n",
      "Epoch 134 Eval Accuracy  0.9174000024795532 training time: 1.2779829502105713\n",
      "Epoch 135 Learning Rate [0.010000000000000002]\n",
      "Epoch 135 Train Accuracy  0.9892799854278564 training time: 7.845682859420776\n",
      "Epoch 135 Eval Accuracy  0.9177999496459961 training time: 1.2134332656860352\n",
      "Epoch 136 Learning Rate [0.010000000000000002]\n",
      "Epoch 136 Train Accuracy  0.9892999529838562 training time: 7.890537738800049\n",
      "Epoch 136 Eval Accuracy  0.9170999526977539 training time: 1.2702713012695312\n",
      "Epoch 137 Learning Rate [0.010000000000000002]\n",
      "Epoch 137 Train Accuracy  0.9890199899673462 training time: 7.811151027679443\n",
      "Epoch 137 Eval Accuracy  0.9163999557495117 training time: 1.252363681793213\n",
      "Epoch 138 Learning Rate [0.010000000000000002]\n",
      "Epoch 138 Train Accuracy  0.9899799823760986 training time: 7.767797231674194\n",
      "Epoch 138 Eval Accuracy  0.9181999564170837 training time: 1.2439055442810059\n",
      "Epoch 139 Learning Rate [0.010000000000000002]\n",
      "Epoch 139 Train Accuracy  0.9904999732971191 training time: 7.937845706939697\n",
      "Epoch 139 Eval Accuracy  0.9174000024795532 training time: 1.2185440063476562\n",
      "Epoch 140 Learning Rate [0.010000000000000002]\n",
      "Epoch 140 Train Accuracy  0.9902399778366089 training time: 7.879667520523071\n",
      "Epoch 140 Eval Accuracy  0.9160999655723572 training time: 1.2075705528259277\n",
      "Epoch 141 Learning Rate [0.010000000000000002]\n",
      "Epoch 141 Train Accuracy  0.9901999831199646 training time: 7.83678674697876\n",
      "Epoch 141 Eval Accuracy  0.9165999889373779 training time: 1.2101032733917236\n",
      "Epoch 142 Learning Rate [0.010000000000000002]\n",
      "Epoch 142 Train Accuracy  0.9899599552154541 training time: 7.83207631111145\n",
      "Epoch 142 Eval Accuracy  0.9160999655723572 training time: 1.2129361629486084\n",
      "Epoch 143 Learning Rate [0.010000000000000002]\n",
      "Epoch 143 Train Accuracy  0.9890799522399902 training time: 7.8491387367248535\n",
      "Epoch 143 Eval Accuracy  0.9185999631881714 training time: 1.2613680362701416\n",
      "Epoch 144 Learning Rate [0.010000000000000002]\n",
      "Epoch 144 Train Accuracy  0.9899799823760986 training time: 7.817555665969849\n",
      "Epoch 144 Eval Accuracy  0.9179999828338623 training time: 1.2220358848571777\n",
      "Epoch 145 Learning Rate [0.010000000000000002]\n",
      "Epoch 145 Train Accuracy  0.9905799627304077 training time: 7.952402591705322\n",
      "Epoch 145 Eval Accuracy  0.9156000018119812 training time: 1.2836227416992188\n",
      "Epoch 146 Learning Rate [0.010000000000000002]\n",
      "Epoch 146 Train Accuracy  0.9907199740409851 training time: 7.80349326133728\n",
      "Epoch 146 Eval Accuracy  0.9142999649047852 training time: 1.258730411529541\n",
      "Epoch 147 Learning Rate [0.010000000000000002]\n",
      "Epoch 147 Train Accuracy  0.9909999966621399 training time: 7.817214250564575\n",
      "Epoch 147 Eval Accuracy  0.9139999747276306 training time: 1.2125442028045654\n",
      "Epoch 148 Learning Rate [0.010000000000000002]\n",
      "Epoch 148 Train Accuracy  0.9904999732971191 training time: 7.807639837265015\n",
      "Epoch 148 Eval Accuracy  0.9151999950408936 training time: 1.237823724746704\n",
      "Epoch 149 Learning Rate [0.010000000000000002]\n",
      "Epoch 149 Train Accuracy  0.9912599921226501 training time: 7.963031530380249\n",
      "Epoch 149 Eval Accuracy  0.9160999655723572 training time: 1.2379639148712158\n",
      "Epoch 150 Learning Rate [0.0010000000000000002]\n",
      "Epoch 150 Train Accuracy  0.9917399883270264 training time: 7.870967388153076\n",
      "Epoch 150 Eval Accuracy  0.9182999730110168 training time: 1.2712738513946533\n",
      "Epoch 151 Learning Rate [0.0010000000000000002]\n",
      "Epoch 151 Train Accuracy  0.9938199520111084 training time: 7.848668336868286\n",
      "Epoch 151 Eval Accuracy  0.9174999594688416 training time: 1.2093827724456787\n",
      "Epoch 152 Learning Rate [0.0010000000000000002]\n",
      "Epoch 152 Train Accuracy  0.9936800003051758 training time: 7.902641296386719\n",
      "Epoch 152 Eval Accuracy  0.9180999994277954 training time: 1.210749626159668\n",
      "Epoch 153 Learning Rate [0.0010000000000000002]\n",
      "Epoch 153 Train Accuracy  0.9946999549865723 training time: 7.8071208000183105\n",
      "Epoch 153 Eval Accuracy  0.9188999533653259 training time: 1.309009313583374\n",
      "Epoch 154 Learning Rate [0.0010000000000000002]\n",
      "Epoch 154 Train Accuracy  0.9947399497032166 training time: 7.933298826217651\n",
      "Epoch 154 Eval Accuracy  0.9164999723434448 training time: 1.283639907836914\n",
      "Epoch 155 Learning Rate [0.0010000000000000002]\n",
      "Epoch 155 Train Accuracy  0.9942599534988403 training time: 7.948786020278931\n",
      "Epoch 155 Eval Accuracy  0.9178999662399292 training time: 1.2499535083770752\n",
      "Epoch 156 Learning Rate [0.0010000000000000002]\n",
      "Epoch 156 Train Accuracy  0.9947199821472168 training time: 7.900979995727539\n",
      "Epoch 156 Eval Accuracy  0.9174000024795532 training time: 1.280088186264038\n",
      "Epoch 157 Learning Rate [0.0010000000000000002]\n",
      "Epoch 157 Train Accuracy  0.995199978351593 training time: 7.791587591171265\n",
      "Epoch 157 Eval Accuracy  0.9179999828338623 training time: 1.2419509887695312\n",
      "Epoch 158 Learning Rate [0.0010000000000000002]\n",
      "Epoch 158 Train Accuracy  0.9945399761199951 training time: 7.883070707321167\n",
      "Epoch 158 Eval Accuracy  0.9174999594688416 training time: 1.2030701637268066\n",
      "Epoch 159 Learning Rate [0.0010000000000000002]\n",
      "Epoch 159 Train Accuracy  0.9951399564743042 training time: 7.711997985839844\n",
      "Epoch 159 Eval Accuracy  0.9188999533653259 training time: 1.2258617877960205\n",
      "Epoch 160 Learning Rate [0.0010000000000000002]\n",
      "Epoch 160 Train Accuracy  0.9948999881744385 training time: 7.823590517044067\n",
      "Epoch 160 Eval Accuracy  0.9172999858856201 training time: 1.2017302513122559\n",
      "Epoch 161 Learning Rate [0.0010000000000000002]\n",
      "Epoch 161 Train Accuracy  0.9948399662971497 training time: 7.862377405166626\n",
      "Epoch 161 Eval Accuracy  0.9178999662399292 training time: 1.2459945678710938\n",
      "Epoch 162 Learning Rate [0.0010000000000000002]\n",
      "Epoch 162 Train Accuracy  0.9950399994850159 training time: 7.839029550552368\n",
      "Epoch 162 Eval Accuracy  0.9185999631881714 training time: 1.232696771621704\n",
      "Epoch 163 Learning Rate [0.0010000000000000002]\n",
      "Epoch 163 Train Accuracy  0.9958199858665466 training time: 7.838410139083862\n",
      "Epoch 163 Eval Accuracy  0.9192000031471252 training time: 1.2079858779907227\n",
      "Epoch 164 Learning Rate [0.0010000000000000002]\n",
      "Epoch 164 Train Accuracy  0.9956599473953247 training time: 7.923547983169556\n",
      "Epoch 164 Eval Accuracy  0.9194999933242798 training time: 1.3091554641723633\n",
      "Epoch 165 Learning Rate [0.0010000000000000002]\n",
      "Epoch 165 Train Accuracy  0.9951799511909485 training time: 8.065742492675781\n",
      "Epoch 165 Eval Accuracy  0.9185000061988831 training time: 1.2401418685913086\n",
      "Epoch 166 Learning Rate [0.0010000000000000002]\n",
      "Epoch 166 Train Accuracy  0.9955999851226807 training time: 7.932264566421509\n",
      "Epoch 166 Eval Accuracy  0.9187999963760376 training time: 1.317624568939209\n",
      "Epoch 167 Learning Rate [0.0010000000000000002]\n",
      "Epoch 167 Train Accuracy  0.9954800009727478 training time: 8.061694383621216\n",
      "Epoch 167 Eval Accuracy  0.9182999730110168 training time: 1.293823480606079\n",
      "Epoch 168 Learning Rate [0.0010000000000000002]\n",
      "Epoch 168 Train Accuracy  0.9949599504470825 training time: 7.929550647735596\n",
      "Epoch 168 Eval Accuracy  0.9186999797821045 training time: 1.2554855346679688\n",
      "Epoch 169 Learning Rate [0.0010000000000000002]\n",
      "Epoch 169 Train Accuracy  0.995199978351593 training time: 7.843331336975098\n",
      "Epoch 169 Eval Accuracy  0.9193999767303467 training time: 1.1904113292694092\n",
      "Epoch 170 Learning Rate [0.0010000000000000002]\n",
      "Epoch 170 Train Accuracy  0.9952600002288818 training time: 7.910175561904907\n",
      "Epoch 170 Eval Accuracy  0.9192000031471252 training time: 1.2576587200164795\n",
      "Epoch 171 Learning Rate [0.0010000000000000002]\n",
      "Epoch 171 Train Accuracy  0.9957599639892578 training time: 8.019365072250366\n",
      "Epoch 171 Eval Accuracy  0.9192999601364136 training time: 1.2516722679138184\n",
      "Epoch 172 Learning Rate [0.0010000000000000002]\n",
      "Epoch 172 Train Accuracy  0.9955199956893921 training time: 7.8600172996521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 Eval Accuracy  0.9199999570846558 training time: 1.2636878490447998\n",
      "Epoch 173 Learning Rate [0.0010000000000000002]\n",
      "Epoch 173 Train Accuracy  0.9950999617576599 training time: 7.834820747375488\n",
      "Epoch 173 Eval Accuracy  0.9194999933242798 training time: 1.203376054763794\n",
      "Epoch 174 Learning Rate [0.0010000000000000002]\n",
      "Epoch 174 Train Accuracy  0.9957000017166138 training time: 7.802417755126953\n",
      "Epoch 174 Eval Accuracy  0.9187999963760376 training time: 1.2212965488433838\n",
      "Epoch 175 Learning Rate [0.0010000000000000002]\n",
      "Epoch 175 Train Accuracy  0.9956799745559692 training time: 7.88286828994751\n",
      "Epoch 175 Eval Accuracy  0.9187999963760376 training time: 1.2459728717803955\n",
      "Epoch 176 Learning Rate [0.0010000000000000002]\n",
      "Epoch 176 Train Accuracy  0.9957000017166138 training time: 7.91748571395874\n",
      "Epoch 176 Eval Accuracy  0.9199000000953674 training time: 1.2548887729644775\n",
      "Epoch 177 Learning Rate [0.0010000000000000002]\n",
      "Epoch 177 Train Accuracy  0.9956799745559692 training time: 8.080787181854248\n",
      "Epoch 177 Eval Accuracy  0.9197999835014343 training time: 1.251988410949707\n",
      "Epoch 178 Learning Rate [0.0010000000000000002]\n",
      "Epoch 178 Train Accuracy  0.9962599873542786 training time: 7.839907884597778\n",
      "Epoch 178 Eval Accuracy  0.9199000000953674 training time: 1.2167701721191406\n",
      "Epoch 179 Learning Rate [0.0010000000000000002]\n",
      "Epoch 179 Train Accuracy  0.9956799745559692 training time: 8.253020763397217\n",
      "Epoch 179 Eval Accuracy  0.9194999933242798 training time: 1.2631640434265137\n",
      "Epoch 180 Learning Rate [0.0010000000000000002]\n",
      "Epoch 180 Train Accuracy  0.9955599904060364 training time: 7.883862495422363\n",
      "Epoch 180 Eval Accuracy  0.9192999601364136 training time: 1.2647182941436768\n",
      "Epoch 181 Learning Rate [0.0010000000000000002]\n",
      "Epoch 181 Train Accuracy  0.9949999451637268 training time: 7.7237560749053955\n",
      "Epoch 181 Eval Accuracy  0.9193999767303467 training time: 1.2467238903045654\n",
      "Epoch 182 Learning Rate [0.0010000000000000002]\n",
      "Epoch 182 Train Accuracy  0.9954999685287476 training time: 7.80785346031189\n",
      "Epoch 182 Eval Accuracy  0.9186999797821045 training time: 1.2481744289398193\n",
      "Epoch 183 Learning Rate [0.0010000000000000002]\n",
      "Epoch 183 Train Accuracy  0.9958599805831909 training time: 7.8834686279296875\n",
      "Epoch 183 Eval Accuracy  0.9180999994277954 training time: 1.2324621677398682\n",
      "Epoch 184 Learning Rate [0.0010000000000000002]\n",
      "Epoch 184 Train Accuracy  0.9959799647331238 training time: 7.977277517318726\n",
      "Epoch 184 Eval Accuracy  0.9195999503135681 training time: 1.2341523170471191\n",
      "Epoch 185 Learning Rate [0.0010000000000000002]\n",
      "Epoch 185 Train Accuracy  0.99617999792099 training time: 7.9400646686553955\n",
      "Epoch 185 Eval Accuracy  0.9179999828338623 training time: 1.3022360801696777\n",
      "Epoch 186 Learning Rate [0.0010000000000000002]\n",
      "Epoch 186 Train Accuracy  0.9960799813270569 training time: 7.961836099624634\n",
      "Epoch 186 Eval Accuracy  0.9190999865531921 training time: 1.2308111190795898\n",
      "Epoch 187 Learning Rate [0.0010000000000000002]\n",
      "Epoch 187 Train Accuracy  0.9959200024604797 training time: 7.880874395370483\n",
      "Epoch 187 Eval Accuracy  0.9179999828338623 training time: 1.2301099300384521\n",
      "Epoch 188 Learning Rate [0.0010000000000000002]\n",
      "Epoch 188 Train Accuracy  0.9955799579620361 training time: 7.820535659790039\n",
      "Epoch 188 Eval Accuracy  0.9187999963760376 training time: 1.2952570915222168\n",
      "Epoch 189 Learning Rate [0.0010000000000000002]\n",
      "Epoch 189 Train Accuracy  0.9956599473953247 training time: 7.917053699493408\n",
      "Epoch 189 Eval Accuracy  0.918999969959259 training time: 1.2628309726715088\n",
      "Epoch 190 Learning Rate [0.0010000000000000002]\n",
      "Epoch 190 Train Accuracy  0.9961999654769897 training time: 7.945339202880859\n",
      "Epoch 190 Eval Accuracy  0.9179999828338623 training time: 1.2329258918762207\n",
      "Epoch 191 Learning Rate [0.0010000000000000002]\n",
      "Epoch 191 Train Accuracy  0.9958999752998352 training time: 7.8424811363220215\n",
      "Epoch 191 Eval Accuracy  0.9178999662399292 training time: 1.2977309226989746\n",
      "Epoch 192 Learning Rate [0.0010000000000000002]\n",
      "Epoch 192 Train Accuracy  0.995959997177124 training time: 7.861550569534302\n",
      "Epoch 192 Eval Accuracy  0.9178999662399292 training time: 1.2919182777404785\n",
      "Epoch 193 Learning Rate [0.0010000000000000002]\n",
      "Epoch 193 Train Accuracy  0.9960999488830566 training time: 8.109122037887573\n",
      "Epoch 193 Eval Accuracy  0.9179999828338623 training time: 1.253788709640503\n",
      "Epoch 194 Learning Rate [0.0010000000000000002]\n",
      "Epoch 194 Train Accuracy  0.9956199526786804 training time: 8.03278660774231\n",
      "Epoch 194 Eval Accuracy  0.9182999730110168 training time: 1.315819501876831\n",
      "Epoch 195 Learning Rate [0.0010000000000000002]\n",
      "Epoch 195 Train Accuracy  0.9960399866104126 training time: 7.955315589904785\n",
      "Epoch 195 Eval Accuracy  0.9192999601364136 training time: 1.290334701538086\n",
      "Epoch 196 Learning Rate [0.0010000000000000002]\n",
      "Epoch 196 Train Accuracy  0.9958599805831909 training time: 7.869446754455566\n",
      "Epoch 196 Eval Accuracy  0.9190999865531921 training time: 1.2172904014587402\n",
      "Epoch 197 Learning Rate [0.0010000000000000002]\n",
      "Epoch 197 Train Accuracy  0.9961400032043457 training time: 8.136683702468872\n",
      "Epoch 197 Eval Accuracy  0.9182999730110168 training time: 1.2202119827270508\n",
      "Epoch 198 Learning Rate [0.0010000000000000002]\n",
      "Epoch 198 Train Accuracy  0.9959200024604797 training time: 7.988774538040161\n",
      "Epoch 198 Eval Accuracy  0.9193999767303467 training time: 1.2676875591278076\n",
      "Epoch 199 Learning Rate [0.0010000000000000002]\n",
      "Epoch 199 Train Accuracy  0.9956799745559692 training time: 7.950868129730225\n",
      "Epoch 199 Eval Accuracy  0.9185000061988831 training time: 1.288707971572876\n"
     ]
    }
   ],
   "source": [
    "import  time \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model = my_model\n",
    "model.train()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9,weight_decay=0.0001)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100,150])\n",
    "\n",
    "#Basic training and evaluation steps are identical\n",
    "#the only difference is that during evaluation mode,\n",
    "#  the model should be set to eval mode and steps should be executed with no_grad\n",
    "def trainAndEval(dsloader,trainingMode=True):\n",
    "    epoch_start_time = time.time()\n",
    "    e_num_correct = 0\n",
    "    e_total_samples = 0\n",
    "    optimizer.zero_grad()  # clear previous gradients\n",
    "    if trainingMode:\n",
    "        modeStr = \"Train\"\n",
    "    else:\n",
    "        modeStr = \"Eval\"\n",
    "    for i, dataBatch in enumerate(dsloader):\n",
    "        load_ts = time.time()\n",
    "        data, target = dataBatch\n",
    "        load_te = time.time()\n",
    "        X = data.to('cuda')\n",
    "        Y = target.to('cuda')\n",
    "\n",
    "        #aprint(\"Shape of X {}. Target shape : {}\",X.shape,Y.shape)\n",
    "        \n",
    "        output_batch = model(X)           # compute model output\n",
    "        #print(\"Output from model {}\",output_batch)\n",
    "        loss = loss_fn(output_batch, Y)  # calculate loss\n",
    "\n",
    "        if trainingMode :\n",
    "            loss.backward()        # compute gradients of all variables wrt loss\n",
    "            optimizer.step()       # perform updates using calculated gradients\n",
    "            optimizer.zero_grad()  # clear  gradients for the next iter\n",
    "\n",
    "        pred_idx = torch.argmax(output_batch,dim=1)\n",
    "        correct = (pred_idx == Y).float().sum()\n",
    "        e_num_correct += correct\n",
    "        e_total_samples += X.shape[0]\n",
    "    epoch_end_time = time.time()\n",
    "    print(\"Epoch {} {} Accuracy  {} training time: {}\".format(epoch,modeStr,e_num_correct.float()/e_total_samples,epoch_end_time-epoch_start_time))\n",
    "    \n",
    "    \n",
    "for epoch in range(200):\n",
    "    print(\"Epoch {} Learning Rate {}\".format(epoch,lr_scheduler.get_lr()))\n",
    "    model.train()\n",
    "    trainAndEval(trainloader,trainingMode=True)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        trainAndEval(testloader,trainingMode=False)\n",
    "    lr_scheduler.step()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MnistResnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
